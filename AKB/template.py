import sys
sys.path.append('AKB')
import icl
import os
import json

class GenerationTemplate:
    """
    Takes a prompt template and provides methods for filling in blanks.
    The format is as follows:
    [APE] is where text will be generated by the LLM.
    [full_DEMO] is where the full demo will be inserted.
    [INPUT] is where the input to the first demo will be inserted.
    [OUTPUT] is where the output from the first demo will be inserted.
    """

    def __init__(self, template):
        self.template = template
        # Check that the template is valid
        # There should be exactly one [APE] token
        # assert self.template.count('[APE]') == 1

    def fill(self, full_demo='', input='', output=''):
        """
        Fills in the template with the given values.
        """
        return self.template.replace('[full_DEMO]', full_demo).replace(
            '[INPUT]', input).replace('[OUTPUT]', output)


# class EvalTemplate:
#     """
#     Takes a prompt template and provides methods for filling in blanks.
#     The format is as follows:
#     [PROMPT] is where the prompt will be inserted.
#     [full_DEMO] is where the full demo will be inserted.
#     [INPUT] is where the input to the first demo will be inserted.
#     [OUTPUT] is where the output from the first demo will be inserted.
#     """

#     def __init__(self, template):
#         self.template = template

#     def fill(self, prompt='', full_demo='', input='', output=''):
#         """
#         Fills in the template with the given values.
#         """
#         return self.template.replace('[PROMPT]', prompt).replace(
#             '[full_DEMO]', full_demo).replace('[INPUT]', input).replace('[OUTPUT]', output)

#     def convert_to_generation_template(self):
#         """
#         Converts the evaluation template to a generation template.
#         """
#         return GenerationTemplate(self.template.replace('[PROMPT]', '[APE]'))


class DemosTemplate:
    """
    Takes a template for the full demo and provides methods for filling in blanks.
    The format is as follows:
    [INPUT], [OUTPUT]

    """

    def __init__(self, template, delimiter='\n\n'):
        self.template = template
        self.delimiter = delimiter

    def fill(self, data):
        """
        Fills in the template with the given values. Data is a tuple of lists.
        """
        demos = ''
        for i, (input_, output_) in enumerate(zip(*data)):
            demos += self.template.replace('[INPUT]', input_).replace(
                '[OUTPUT]', output_)

            if i != len(data[0]) - 1:
                demos += self.delimiter

        return demos

import re

class Template:
    _placeholders = {
        'task_description': '[task_description]',
        'rules': '[HINTS]',
        'question': '[QUESTION]'
    }
    def __init__(self, task, task_type, task_description, rules, question, infer_mode, component, ICL_method, demo_file=None):
        self.task = task
        self.task_type = task_type
        self.question = question
        self.task_description = task_description
        self.rules = rules
        self.component = component
        self.ICL_method = ICL_method
        if 'giv' in ICL_method:
            self.demos = _template[task]['demos']
        elif ICL_method:
            icl.build_faiss(demo_file, ICL_method)

        self._template = _template['template-llama']
        if infer_mode=='reason':
            self.question = self.question.replace('\nChoose your answer from: [Yes, No]', '')
            self.question = self.question.replace('\nAnswer only the name of the brand.', '')
            self._template =  _template['template_r']

        self._demo_template = 'Input: [INPUT]\nOutput: [OUTPUT]'
        self._prompt_gen_template = _template['prompt_gen_template']

    def get_component(self, gen):
        if gen == 'task_description':
            return self.task_description
        elif gen == 'rules':
            return self.rules
        elif gen == 'question':
            return self.question
        elif gen is None:
            return ""
        else:
            raise ValueError(f"[ERROR] {gen} is not a availabel component.")
        
    def update(self, gen, content):
        def escape_placeholders(input_string):
            # 匹配单大括号包裹的占位符，并排除已转义的双大括号形式
            pattern = r"(?<!{){([^{}]+)}(?!})"
            # 将匹配的部分替换为双大括号形式
            escaped_string = re.sub(pattern, r"{{\1}}", input_string)
            return escaped_string
        
        content = escape_placeholders(content)
        if gen == 'task_description':
            self.task_description = content
        elif gen == 'rules':
            self.rules = content
        elif gen == 'question':
            self.question = content
        else:
            raise ValueError(f"[ERROR] {gen} is not a availabel component.")


    def prompt_gen_template(self, gen):
        task_description = self.task_description
        rules = self.rules
        question = self.question
        
        gen_token = self._placeholders[gen]

        return self._prompt_gen_template.format(
            token = gen_token, 
            task_description = task_description,
            rules = rules,
            question = question if gen!='question' else '',
            )
    

    def eval_template(self, gen=None):
        task_description = self.task_description
        rules = self.rules
        question = self.question
        # if self.task_type in [0, 5]: # ED and AVE are instance-wise
        #     self._template = self._template.replace('\n\n{question}',"")

        if gen == 'task_description':
            task_description = '{prompt}'
        elif gen == 'rules':
            rules = '{prompt}'
        elif gen == 'question':
            question = '{prompt}'
        elif gen is None:
            pass
        else:
            raise ValueError(f"{gen} is not applicable.")

        result = self._template.format(task_description=task_description, rules=rules, question=question)
        
        result = result.replace('{input}', f"{self.get_demos(None)}{{input}}")

        return result

    def get_demos(self, query=None):
        if 'giv' in self.ICL_method:
            # demos = [demo['output'] for demo in self.demos]
            demos = self.demos
        elif self.ICL_method and query:
            demos = icl.get_demos(query, self.ICL_method)
        else:
            return ""

        demo_string = ""
        for demo in reversed(demos):
            demo_question = self.question.format(
                attribute = demo.get('attribute', None),
                value = demo.get('value', None),
            )
            # demos = f"[INST]\n\n{demo['instruction']}\n\n[\\INST]\n\n{demo['output']}\n\n" + demos
            demo_string = f"[INST]\n\n{demo['input'] if self.task_type==5 else demo['entity']}\n{demo_question}\n\n[/INST]\n\n{demo['output']}\n\n" + demo_string
            # demos = "<|start_header_id|>user<|end_header_id|>" + demos
        return demo_string
    
    def fill(self, input='', **kwargs):
        if self.ICL_method:
            template = self._template.replace('{input}', f"{self.get_demos(kwargs['input'])}{{input}}")
        else:
            template = self._template

        template = template.format(
            task_description=self.task_description,
            rules=self.rules,
            question=self.question,
            input=input, 
        )

#                 # TableLlama
#         template = '''Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.

# ### Instruction:
# {instruction}

# ### Input:
# {input}

# ### Question:
# {question}

# ### Response:
# '''
        # template = template.format(
        #     instruction=self.task_description,
        #     input=input,
        #     question=self.question,
        # )

        return template.format(
            input=input, 
            comma=kwargs.get('comma',None),
            attribute=kwargs.get('attribute',None),
            value=kwargs.get('value',None),
        )

    def export(self, template, data, export_as_demo):
        export_data = []

        for id, item in enumerate(data):
            query = self.fill(
                # input=item['input'].strip() if self.task_type in [0, 5] else item['entity'],
                input=item['entity'],
                comma=_sotab_comma.get(item.get('table_type', None), None),
                attribute=item.get('attribute', None),
                value=item.get('value', None),
            )
            export_data.append({
                'dataset': item['dataset'],
                'instruction': query,
                'input': item['entity']+'\n'+template.get_component('question')+'\n' if export_as_demo else "",
                'entity': item['entity'],
                'output': item['output'],
                'task_type': item['task_type'],
            })
            if 'value' in item: # for calculation the recall of DC
                export_data[-1]['value'] = item['value']
                export_data[-1]['attribute'] = item['attribute']
            if 'label_list' in item: # for calculation the recall of DC
                export_data[-1]['label_list'] = item['label_list']
            if 'table_type' in item:
                export_data[-1]['table_type'] = item['table_type']
                

        return export_data
    

class GenTemplate(Template):
    def __init__(self, prompt_gen_template, task_type):
        self._template = prompt_gen_template
        self.task_type = task_type

    def fill(self, **kwargs):
        return self._template.format(
            full_demo=kwargs.get('full_demo',None), 
            input=kwargs.get('input',None),
            output=kwargs.get('output',None),
            comma=kwargs.get('comma',None),
            attribute=kwargs.get('attribute',None),
            value=kwargs.get('value',None),
        )
    

class EvalTemplate(Template):
    def __init__(self, template: Template):
        self._template = template.eval_template(template.component)
        self.task_type = template.task_type
        self.ICL_method = template.ICL_method
        # for ICL
        self.demos = getattr(template, 'demos', None)
        self.task_description = template.task_description
        self.rules = template.rules
        self.question = template.question


    def fill(self, **kwargs):
        if self.ICL_method:
            demo_string = self.get_demos(kwargs['input']).replace('{', '{{').replace('}', '}}') # KeyError for template.format
            template = self._template.replace('{input}', f"{demo_string}{{input}}")
        else:
            template = self._template

        return template.format(
            prompt=kwargs.get('prompt',None), 
            input=kwargs.get('input',None),
            output=kwargs.get('output',None),
            comma=kwargs.get('comma',None),
            attribute=kwargs.get('attribute',None),
            value=kwargs.get('value',None),
        )
    
    def fill_tablellama(self, **kwargs):
        template = '''Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.

### Instruction:
{task_description}

### Input:
{input}

### Question:
{question}

### Response:
''',
        print(f"[Warning] template of TableLlama is used when exporting!!!")

        def parse_entities(s):
            # Find all entities enclosed in square brackets
            entities = re.findall(r'\[(.*?)\]', s, re.DOTALL)
            results = []
            for entity in entities:
                # Extract attribute-value pairs within each entity
                pairs = re.findall(r'([^:]+): "(.*?)"', entity)
                # Clean up and build a dictionary for each entity
                entity_dict = {k.strip(): v for k, v in pairs}
                results.append(entity_dict)
            return results

        def dict_to_string(data):
            # Initialize the output string
            output = ''
            
            # Example header (You can modify this based on your requirements)
            output += '[TLE] The Wikipedia page is about List of Air India FC managers. The Wikipedia section is about Statistics. [TAB] '
            
            # Extract column headers from keys of the first dictionary
            if isinstance(data, list) and len(data) > 0:
                headers = list(data[0].keys())
            elif isinstance(data, dict):
                headers = list(data.keys())
                data = [data]  # Convert dict to list for uniform processing
            else:
                return "Invalid data format"
            
            # Build the column header string
            output += 'col: | ' + ' | '.join(headers) + ' | '
            
            # Iterate over each row and build the string
            for idx, row in enumerate(data, 1):
                output += f'[SEP] row {idx}: | '
                row_values = [str(row.get(header, '')) for header in headers]
                output += ' | '.join(row_values) + ' | '
            
            return output

        entity_dict = parse_entities(kwargs['input'])
        input_string = dict_to_string(entity_dict)

        return template.format(
            task_description=self.task_description,
            question=self.question,
            input=input_string, 
        )





    def convert_to_generation_template(self):
        """
        Converts the evaluation template to a generation template.
        """
        raise RuntimeError("该函数已废弃，请更换为新的实现。")
        return GenerationTemplate(self._template.replace('[PROMPT]', '[APE]'))


class ErrorTemplate(Template):
    def __init__(self, task, task_type, task_description, rules, question, component, version=''):
        self.task = task
        self.task_type = task_type
        self.component = component
        self.question = question
        self.task_description = task_description
        self.rules = rules
        self._prompt_templates = [_template['prompt_template'].format(
            task_description=task_description,
            rules=rules,
            question=question,
        )]
        self._template = _template[f'prompt_refine_template{version}'].format(
            prompt = self.get_prompt(),
            token = self._placeholders[component],
            end_token = self._placeholders[component].replace('[','[\\')
        )
        self._demo_template = _template['error_string']
        self._feedback_template = _template['error_feedback']

    def get_prompt(self, idx=-1):
        return self._prompt_templates[idx]
    
    def get_history_string(self):
        string = ""
        for idx in range(len(self._prompt_templates)):
            string  = string + '\n' + self.get_prompt(idx)

    def get_demo_string(self, error_data):
        error_string = ""
        for idx, data in enumerate(error_data):
            if 'input' not in data:
                print(f"[ERROR] {data}")
            error_string = error_string + '\n\n' + self._demo_template.format(
                index = str(idx),
                input = data['input'],
                response = data['response'],
                label = data['output'],
                prediction = data['prediction']
            )

        return error_string

    def prefill(self, error_data):
        return self._feedback_template.format(
            prompt=self.get_prompt(),
            error_string=self.get_demo_string(error_data),
        )
        
    def fill(self, error_data, feedback, comma='{{comma}}', attribute='{{attribute}}', value='{{value}}'):
        return self._template.format(
            error = self.get_demo_string(error_data),
            error_feedback = feedback,
            trajectory_prompts = self.get_history_string(),
            comma=comma,
            attribute=attribute,
            value=value,
        )


_template = {
    "prompt_template": '''[TASK_DESCRIPTION] {task_description}

[HINTS] {rules}

[INPUT] 

[QUESTION] {question}''',

    'template': '''You are an AI assistant that follows instruction extremely well. User will give you a question. Your task is to answer as faithfully as you can.

[INST]

{task_description}
{rules}

{{input}}

{question}

[\\INST]

''',    
    'template-llama': '''{task_description}
{rules}
{{input}}
{question}''',
    'template_r': '''You are an AI assistant that follows instruction extremely well. User will give you a question. Your task is to answer as faithfully as you can. While answering, provide detailed explanation and justify your answer.

[INST]

{task_description}
{rules}

{{input}}

{question}
Provide a detailed reasoning that explains how to arrive at the answer.
After your reasoning, provide your final answer in a separate line in the format of \"Final answer: Yes / No\".

[\\INST]

''',

    "prompt_gen_template": '''You are a prompt generation assistant. Your task is to complete the `{token}` section of a given prompt template based on the provided `Input` and `Output` pairs.

### Template: 

[TASK_DESCRIPTION] {task_description}

[HINTS] {rules}

[INPUT] {{input}}

[QUESTION] {question}

### Example:

{{full_demo}}

Generate only the `{token}` part of the template, ensuring it accurately reflects the relationship demonstrated by the `Input` and `Output` pairs.
{token}''',
    "prompt_gen_template_r": '''Write a short hints in a paragraph insert into the following prompt that help solving the following data preparation task.

### Prompt:

{task_description}

[HINTS] {rules}

[INPUT] {{input}}

{question}

### Examples:

{{full_demo}}

{token}''',

### error feedback
    "error_string": '''### Wrong example <{index}>:
The model’s input is:
{input}
The model’s response is:
{response}
The correct label is: {label}
The model’s prediction is {prediction}''',
    "error_feedback": '''I’m writing prompts for a language model designed for a task.
My current prompt is:

{prompt}

But this prompt gets the following examples wrong:

{error_string}

For each wrong example, carefully examine each question and wrong answer step by step, provide comprehensive and different reasons why the prompt leads to the wrong answer. At last, based on all these reasons, summarize and list all the aspects that can improve the prompt.
''',
    "prompt_refine_template":'''I’m writing prompts for a language model designed for data preparation task.
My current prompt is:

{prompt}

But this prompt gets the following examples wrong:

{{error}}

Based on these errors, the problems with this prompt and the reasons are:
{{error_feedback}}

There is a list of former prompts including the current prompt, and each prompt is modified from its former prompts:
{{trajectory_prompts}}

Based on the above information, please write a new {token} following these guidelines:
1. The new {token} should solve the current prompt’s problems.
2. The new {token} should evolve based on the current prompt.
3. Each new {token} should be wrapped with {token} and {end_token}.
The new prompt is:
{token}''',
}

def register_templates_from_folder(folder_path):
    """
    遍历给定文件夹中的所有 JSON 文件，将文件名作为键，内容作为值加入到 _template 字典中。
    
    :param folder_path: 包含 JSON 文件的文件夹路径
    """
    global _template  # 声明使用全局变量 _template
    if not os.path.isdir(folder_path):
        raise ValueError(f"The provided path '{folder_path}' is not a valid directory.")
    
    for file_name in os.listdir(folder_path):
        if file_name.endswith('.json'):
            file_path = os.path.join(folder_path, file_name)
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = json.load(f)
                key = os.path.splitext(file_name)[0]  # 去掉文件扩展名
                _template[key] = content
            except (json.JSONDecodeError, IOError) as e:
                print(f"Error loading JSON file '{file_name}': {e}")

register_templates_from_folder('./AKB/templates')

_sotab_comma = {
    "Restaurant": "time, day of week, country, locality of address, telephone, name of restaurant, postal code, region of address, coordinate, description of restaurant, payment accepted, price range, review",
    "Event": "date and time, name of event, description of event, event status, event attendance mode, currency, organization, telephone, date",
    "Hotel": "name of hotel, description of hotel, telephone, email, fax number, postal code, country, time, locality of address, location feature, price range, rating, photograph, review, payment accepted",
    "MusicRecording": "name of music recording, name of music album, duration, music artist"
}

_sotab_map = {
    "locality of address": ["addressLocality", "locality of address", "localities of address"],
    "postal code": ["postalCode", "postal code"],
    "region of address": ["addressRegion", "region of address"],
    "country": ["Country", "country"],
    "price range": ["priceRange", "price range"],
    "name of hotel": ["Hotel/name", "name of hotel", "name of hotels", "name of aparthotel", "hotel name"],
    "telephone": ["telephone", "phone number"],
    "fax number": ["faxNumber", "fax number"],
    "date": ["Date", "date", "end date"],
    "name of restaurant": ["Restaurant/name", "name of restaurant"],
    "payment accepted": ["paymentAccepted", "payment accepted", "payment"],
    "day of week": ["DayOfWeek", "day of week"],
    "review": ["Review", "review"],
    "organization": ["Organization", "organization", "name of organization"],
    "date and time": ["DateTime", "date and time"],
    "music artist": ["MusicArtistAT", "music artist", "name of music artist"],
    "name of music album": ["MusicAlbum/name", "music album", "name of album", "music album", "name of music album"],
    "name of music recording": ["MusicRecording/name", "name of music recording", "music recording", "name of song"],
    "photograph": ["Photograph", "photograph"],
    "coordinate": ["CoordinateAT", "coordinate"],
    "name of event": ["Event/name", "event name", "name of event"],
    "event attendance mode": ["EventAttendanceModeEnumeration", "event attendance mode"],
    "event status": ["EventStatusType", "event status", "event attendance mod"],
    "currency": ["currency", ],
    "email": ["email", "email address"],
    "time": ["Time", "time", "check-in time", "check-out time", "time of check-in", "time of check-out", "check in time", 'check out time'],
    "location feature": ["LocationFeatureSpecification", "location feature", "description of hotel amenities", "description of hotel amenities", "amenities", "hotel amenities", "amenities of hotel room", "hotel features"],
    "duration": ["Duration", "duration", "duration of music recording or video"],
    "description of event": ["Event/description", "description of event", "event description", "descriptions of events"],
    "description of restaurant": ["Restaurant/description", "description of restaurant"],
    "description of hotel": ["Hotel/description", "description of hotel", "description of hotels"],
    "rating": ["Rating", "rating"],
}

_flipkart_map = {
    "Vaishali Bindi and Bangles": ["vaishali"],
    "totalcare Expert": ["totalcare"],
    "Wow!": ["wow"],
    "Uptownie Lite": ["uptownie"],
    "Vidhya Kangan": ["vidhya"],
    "Durian": ["durian georgia"],
    "Mahek Saree": ["mahek"],
    "Yuccabe Italia": ["yuccabe"],
    "Xtreme": ["xtreme mb"],
}



