generation:
  num_subsamples: 5
  num_demos: 3
  num_prompts_per_subsample: 1
  model:
    name: GPT_forward
    batch_size: 1
    gpt_config:
      model: gpt-4o
      # model: Mistral-7B-OpenOrca
      # model: gpt-3.5-turbo-instruct
      temperature: 0.9
      max_tokens: 100
      top_p: 0.9
      frequency_penalty: 0.0
      presence_penalty: 0.0
evaluation:
  method: f1_score
  num_samples: 17
  num_few_shot: 1
  model:
    name: GPT_forward
    batch_size: 4
    gpt_config:
      model: /share/home/12351018/pre-train/Mistral-7B-Instruct-v0.2
      temperature: 0.7
      max_tokens: 30
      top_p: 1.0
      frequency_penalty: 0.0
      presence_penalty: 0.0
demo:
  model:
    name: GPT_forward
    batch_size: 500
    gpt_config:
      model: Mistral-7B
      temperature: 0.7
      max_tokens: 200
      top_p: 1.0
      frequency_penalty: 0.0
      presence_penalty: 0.0
